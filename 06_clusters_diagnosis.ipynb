{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "886c36f6-1c5e-47a4-a055-91cc15b8f67e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3078c5fb-6336-4b3a-9ae5-65ba6254a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f3c9f2e-8e67-47de-8e99-a05833935ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root:  /Users/yizj/Desktop/hbn_project\n",
      "Core data   :  /Users/yizj/Desktop/hbn_project/data/processed/hbn_core_view_v1.csv\n",
      "Clusters    :  /Users/yizj/Desktop/hbn_project/results/kmeans_model/cluster_assignments.csv\n",
      "Diag flags  :  /Users/yizj/Desktop/hbn_project/data/processed/hbn_diag_flags_neuro_anx.csv\n",
      "Results dir :  /Users/yizj/Desktop/hbn_project/results/kmeans_diagnosis\n"
     ]
    }
   ],
   "source": [
    "def find_project_root(start: Path | None = None) -> Path:\n",
    "    \"\"\"Return the repo root by searching upward for markers.\"\"\"\n",
    "    p = (start or Path.cwd()).resolve()\n",
    "    markers = {\".git\", \"environment.yml\", \"README.md\"}\n",
    "    while True:\n",
    "        if any((p / m).exists() for m in markers):\n",
    "            return p\n",
    "        if p.parent == p:\n",
    "            # fallback: use start if nothing found\n",
    "            return (start or Path.cwd()).resolve()\n",
    "        p = p.parent\n",
    "\n",
    "# Allow manual override via env var if needed\n",
    "ROOT = Path(os.environ.get(\"HBN_PROJ_ROOT\", find_project_root()))\n",
    "\n",
    "# --- Paths for INPUT data ---\n",
    "CORE_PATH   = ROOT / \"data\" / \"processed\" / \"hbn_core_view_v1.csv\"\n",
    "CLUSTER_PATH = ROOT / \"results\" / \"kmeans_model\" / \"cluster_assignments.csv\"\n",
    "FLAGS_PATH  = ROOT / \"data\" / \"processed\" / \"hbn_diag_flags_neuro_anx.csv\"\n",
    "\n",
    "# --- Paths for OUTPUT (this notebook) ---\n",
    "RESULTS_DIR = ROOT / \"results\" / \"kmeans_diagnosis\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MERGED_PROCESSED_PATH = ROOT / \"data\" / \"processed\" / \"hbn_core_clusters_diag.csv\"\n",
    "MERGED_INTERIM_PATH   = ROOT / \"data\" / \"interim\"   / \"hbn_core_clusters_diag.csv\"\n",
    "\n",
    "print(\"Project root: \", ROOT)\n",
    "print(\"Core data   : \", CORE_PATH)\n",
    "print(\"Clusters    : \", CLUSTER_PATH)\n",
    "print(\"Diag flags  : \", FLAGS_PATH)\n",
    "print(\"Results dir : \", RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "658256b4-f81f-462b-aa10-db74e0a2c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core = pd.read_csv(CORE_PATH)\n",
    "clusters = pd.read_csv(CLUSTER_PATH)\n",
    "diag_flags = pd.read_csv(FLAGS_PATH)\n",
    "\n",
    "# Standardize ID in all three\n",
    "for frame in [df_core, clusters, diag_flags]:\n",
    "    frame[\"_EID\"] = frame[\"_EID\"].astype(str).str.upper().str.strip()\n",
    "\n",
    "# Merge core + clusters\n",
    "df_core = df_core.merge(clusters[[\"_EID\", \"cluster\"]], on=\"_EID\", how=\"inner\")\n",
    "\n",
    "# Merge diagnosis flags\n",
    "df_all = df_core.merge(diag_flags, on=\"_EID\", how=\"left\")\n",
    "\n",
    "df_all.shape, df_all.head()\n",
    "df_all.to_csv(MERGED_PROCESSED_PATH, index=False)  # or MERGED_INTERIM_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9228ddda-8bd3-4fa1-91c8-da8032dc2895",
   "metadata": {},
   "source": [
    "# Prevalence & Maintanence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb41af15-f3a6-4830-ad63-b31827eb41a1",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "397f5fc1-d214-4b14-a8c4-a5a5e93dd0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramers_v_bias_corrected(table: pd.DataFrame) -> float:\n",
    "    chi2, _, _, _ = chi2_contingency(table)\n",
    "    n = table.to_numpy().sum()\n",
    "    r, k = table.shape\n",
    "    phi2 = chi2 / n\n",
    "    # bias correction\n",
    "    phi2_corr = max(0, phi2 - (k - 1)*(r - 1)/(n - 1))\n",
    "    r_corr = r - (r - 1)**2 / (n - 1)\n",
    "    k_corr = k - (k - 1)**2 / (n - 1)\n",
    "    return np.sqrt(phi2_corr / min((k_corr - 1), (r_corr - 1)))\n",
    "\n",
    "def chi2_cramers_v(x: pd.Series, y: pd.Series):\n",
    "    \"\"\"Convenience wrapper: returns chi2, p, dof, CramÃ©r's V (bias-corrected).\"\"\"\n",
    "    tab = pd.crosstab(x, y)\n",
    "    chi2, p, dof, _ = chi2_contingency(tab)\n",
    "    V = cramers_v_bias_corrected(tab)\n",
    "    return chi2, p, dof, V, tab\n",
    "\n",
    "def standardized_residuals_from_table(obs: pd.DataFrame) -> pd.DataFrame:\n",
    "    chi2, p, dof, expected = chi2_contingency(obs.values)\n",
    "    resid = (obs.values - expected) / np.sqrt(expected)\n",
    "    return pd.DataFrame(resid, index=obs.index, columns=obs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c2751-3626-44a9-8d8d-c9271db18576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
